{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"03-models_pretrained_and_more (1)-VGG.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7t2SVQopFVIW","colab_type":"text"},"source":["## Model architecture tuning & score optimization\n","\n","\n","Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n","\n","Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n","\n","For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n","In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n","\n","ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."]},{"cell_type":"code","metadata":{"id":"olzS5x8RFbeI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0d35a291-818b-46fd-a12d-004ee3edd3f2","executionInfo":{"status":"ok","timestamp":1569410161000,"user_tz":-540,"elapsed":778,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QCA9Egx2FVIY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"182b42b7-fbf3-4411-c262-f903eb4a9dc2","executionInfo":{"status":"ok","timestamp":1569410161745,"user_tz":-540,"elapsed":1443,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["import os\n","\n","os.chdir('/content/drive/My Drive/Colab Notebooks/dive/Sprint19')\n","print(os.getcwd())"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/dive/Sprint19\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x2PJc71eFVId","colab_type":"code","colab":{}},"source":["import gc\n","import glob\n","import os\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from tqdm import tqdm\n","\n","from keras import optimizers\n","from keras.callbacks import *\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.layers import *\n","from keras.models import Model, load_model, save_model\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\n","from keras.applications.resnet50 import ResNet50, preprocess_input\n","\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing import image\n","from keras.applications.vgg16 import preprocess_input\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIK10v9tFVIg","colab_type":"code","colab":{}},"source":["plt.rcParams['figure.figsize'] = (12, 9)\n","# plt.style.use('ggplot')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6o3qsuirFVIj","colab_type":"code","colab":{}},"source":["def compute_coverage(df, masks):\n","    \n","    df = df.copy()\n","    \n","    def cov_to_class(val):\n","        for i in range(0, 11):\n","            if val * 10 <= i:\n","                return i\n","\n","    # Output percentage of area covered by class\n","    df['coverage'] = np.mean(masks, axis=(1, 2))\n","    # Coverage must be split into bins, otherwise stratified split will not be possible,\n","    # because each coverage will occur only once.\n","    df['coverage_class'] = df.coverage.map(\n","        cov_to_class)\n","\n","    return df\n","\n","\n","def create_depth_abs_channels(image_tensor):\n","    image_tensor = image_tensor.astype(np.float32)\n","    h, w, c = image_tensor.shape\n","    for row, const in enumerate(np.linspace(0, 1, h)):\n","        image_tensor[row, :, 1] = const\n","    image_tensor[:, :, 2] = (\n","        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n","\n","    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n","    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n","    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n","    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n","    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n","\n","    return image_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uiqugBe4FVIn","colab_type":"text"},"source":["### Data loading & depth merge:"]},{"cell_type":"code","metadata":{"id":"2K2pq3JdFVIo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"b5bd4106-8e38-4dbc-ccee-2d8edc1ae764","executionInfo":{"status":"ok","timestamp":1569410161749,"user_tz":-540,"elapsed":1398,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["train = pd.read_csv('Salt/train.csv')\n","test = pd.read_csv('Salt/sample_submission.csv')\n","depth = pd.read_csv('Salt/depths.csv')\n","\n","#train_src = '../input/train/'\n","\n","print('train:\\n{}'.format(train.head()))\n","print('\\ntest:\\n{}'.format(test.head()))\n","\n","\n","train = train.merge(depth, how='left', on='id')\n","test = test.merge(depth, how='left', on='id')\n","\n","train = train.head(300)\n","\n","print('\\n{}'.format(train.head()))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["train:\n","           id                                           rle_mask\n","0  575d24d81d                                                NaN\n","1  a266a2a9df                                          5051 5151\n","2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n","3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n","4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n","\n","test:\n","           id rle_mask\n","0  155410d6fa      1 1\n","1  78b32781d1      1 1\n","2  63db2a476a      1 1\n","3  17bfcdb967      1 1\n","4  7ea0fd3c88      1 1\n","\n","           id                                           rle_mask    z\n","0  575d24d81d                                                NaN  843\n","1  a266a2a9df                                          5051 5151  794\n","2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n","3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n","4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YDee79XCFVIw","colab_type":"text"},"source":["### Load images and masks, examine random sample:"]},{"cell_type":"code","metadata":{"id":"jCZ3RsWZFVIx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8848be38-5e45-4453-feed-2beb741a089a","executionInfo":{"status":"ok","timestamp":1569410164199,"user_tz":-540,"elapsed":3833,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["X_train = np.asarray(\n","    [cv2.imread('Salt/traindata/images/{}.png'.format(x), 0) for x in train.id.tolist()[:300]], \n","    dtype=np.uint8) / 255.\n","y_train = np.asarray(\n","    [cv2.imread('Salt/traindata/masks/{}.png'.format(x), 0) for x in train.id.tolist()[:300]],\n","    dtype=np.uint8) / 255.\n","\n","print(X_train.shape, y_train.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["(300, 101, 101) (300, 101, 101)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"FiThfe5MFVI0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":373},"outputId":"2bf49920-b9fb-4a69-fd08-90821813225c","executionInfo":{"status":"ok","timestamp":1569410164539,"user_tz":-540,"elapsed":4159,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["random_index = np.random.randint(0, X_train.shape[0])\n","\n","fig, ax = plt.subplots(1, 2)\n","\n","ax[0].imshow(X_train[random_index], cmap='gray')\n","ax[1].imshow(y_train[random_index], cmap='gray')"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f50db9b1128>"]},"metadata":{"tags":[]},"execution_count":18},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAI/z/GeP9twucQbQAAAAASUVORK5CYII=\n","text/plain":["<Figure size 864x648 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"xMcJ7gY8FVI3","colab_type":"text"},"source":["### Compute salt coverage (this will serve as a basis for stratified split):"]},{"cell_type":"code","metadata":{"id":"CByDPBfXFVI3","colab_type":"code","colab":{}},"source":["train = compute_coverage(train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ADxwwcvFVI7","colab_type":"text"},"source":["### Prepare data for training:"]},{"cell_type":"code","metadata":{"id":"DF5wPvfyFVI8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"371aa984-ce22-4f05-ec29-dba6ed5f1bf4","executionInfo":{"status":"ok","timestamp":1569410165513,"user_tz":-540,"elapsed":5095,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["kfold = StratifiedKFold(n_splits=5, random_state=1337)\n","\n","# Add channel features\n","X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n","X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n","\n","# Resize to 224x224, default ResNet50 image size\n","X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n","y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n","\n","\n","for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n","    \n","    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n","    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n","    \n","    break\n","    \n","\n","y_tr = np.expand_dims(y_tr, axis=-1)\n","y_val = np.expand_dims(y_val, axis=-1)\n","\n","print(X_tr.shape, y_tr.shape)\n","print(X_val.shape, y_val.shape)\n","\n","\n","del X_train_ch, y_resized\n","del X_resized\n","gc.collect()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(234, 224, 224, 3) (234, 224, 224, 1)\n","(66, 224, 224, 3) (66, 224, 224, 1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["106"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"IiSFnQsqFVI-","colab_type":"text"},"source":["### Loss functions & metric:"]},{"cell_type":"code","metadata":{"id":"v0akkoDRFVI_","colab_type":"code","colab":{}},"source":["from keras.losses import binary_crossentropy\n","\n","\n","# Dice & combined\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred = K.cast(y_pred, 'float32')\n","    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n","    intersection = y_true_f * y_pred_f\n","    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n","    return score\n","\n","\n","def dice_loss(y_true, y_pred):\n","    smooth = 1.\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = y_true_f * y_pred_f\n","    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","    return 1. - score\n","\n","\n","def bce_dice_loss(y_true, y_pred):\n","    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","\n","\n","def bce_logdice_loss(y_true, y_pred):\n","    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n","\n","\n","\n","# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    gts = tf.reduce_sum(gt_sorted)\n","    intersection = gts - tf.cumsum(gt_sorted)\n","    union = gts + tf.cumsum(1. - gt_sorted)\n","    jaccard = 1. - intersection / union\n","    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n","    return jaccard\n","\n","\n","# --------------------------- BINARY LOSSES ---------------------------\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        def treat_image(log_lab):\n","            log, lab = log_lab\n","            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n","            log, lab = flatten_binary_scores(log, lab, ignore)\n","            return lovasz_hinge_flat(log, lab)\n","        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n","        loss = tf.reduce_mean(losses)\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","\n","    def compute_loss():\n","        labelsf = tf.cast(labels, logits.dtype)\n","        signs = 2. * labelsf - 1.\n","        errors = 1. - logits * tf.stop_gradient(signs)\n","        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n","        gt_sorted = tf.gather(labelsf, perm)\n","        grad = lovasz_grad(gt_sorted)\n","        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n","        return loss\n","\n","    # deal with the void prediction case (only void pixels)\n","    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n","                   lambda: tf.reduce_sum(logits) * 0.,\n","                   compute_loss,\n","                   strict=True,\n","                   name=\"loss\"\n","                   )\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = tf.reshape(scores, (-1,))\n","    labels = tf.reshape(labels, (-1,))\n","    if ignore is None:\n","        return scores, labels\n","    valid = tf.not_equal(labels, ignore)\n","    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n","    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n","    return vscores, vlabels\n","\n","\n","def lovasz_loss(y_true, y_pred):\n","    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n","    #logits = K.log(y_pred / (1. - y_pred))\n","    logits = y_pred #Jiaxin\n","    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n","    return loss\n","\n","\n","# IoU metric for observation during training\n","# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n","def get_iou_vector(A, B):\n","    # Numpy version    \n","    batch_size = A.shape[0]\n","    metric = 0.0\n","    for batch in range(batch_size):\n","        t, p = A[batch], B[batch]\n","        true = np.sum(t)\n","        pred = np.sum(p)\n","        \n","        # deal with empty mask first\n","        if true == 0:\n","            metric += (pred == 0)\n","            continue\n","        \n","        # non empty mask case.  Union is never empty \n","        # hence it is safe to divide by its number of pixels\n","        intersection = np.sum(t * p)\n","        union = true + pred - intersection\n","        iou = intersection / union\n","        \n","        # iou metrric is a stepwise approximation of the real iou over 0.5\n","        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n","        \n","        metric += iou\n","        \n","    # teake the average over all images in batch\n","    metric /= batch_size\n","    return metric\n","\n","\n","def my_iou_metric(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n","\n","\n","# For Lovash loss\n","def my_iou_metric_2(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GSXrwgOlFVJB","colab_type":"text"},"source":["### Encoder features - ResNet50:\n","\n","In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n","Default input size will be assumed, which is (224, 224, 3).\n","Layers will be as follows:\n","\n","- 'activation_1', shape: (None, 112, 112, 64)\n","- 'activation_10', shape: (None, 56, 56, 256)\n","- 'activation_22', shape: (None, 28, 28, 512)\n","- 'activation_40', shape: (None, 14, 14, 1024)\n","- 'activation_49', shape: (None, 7, 7, 2048)\n","\n","One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."]},{"cell_type":"markdown","metadata":{"id":"fQMrTEQgFVJC","colab_type":"raw"},"source":["base_model = ResNet50(input_shape=input_size, include_top=False)\n","base_model.summary()"]},{"cell_type":"code","metadata":{"id":"dsL-I6ZGFVJD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0783527b-b9e5-46a0-9179-52a7552198bf","executionInfo":{"status":"ok","timestamp":1569410180060,"user_tz":-540,"elapsed":19619,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["base_model = ResNet50()\n","base_model.summary()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","102858752/102853048 [==============================] - 1s 0us/step\n","Model: \"resnet50\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n","__________________________________________________________________________________________________\n","fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n","==================================================================================================\n","Total params: 25,636,712\n","Trainable params: 25,583,592\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"rEyIDhrLFVJF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":969},"outputId":"2bc2e350-6cfb-4a1f-c088-6565744d8ca7","executionInfo":{"status":"ok","timestamp":1569410188762,"user_tz":-540,"elapsed":28310,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["base_model2 = VGG16()\n","base_model2.summary()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 6s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BA7UGXluFVJI","colab_type":"text"},"source":["### Decoder blocks:\n","\n","Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n","For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."]},{"cell_type":"code","metadata":{"id":"f1lNCNPOFVJK","colab_type":"code","colab":{}},"source":["# Basic decoder block with Conv, BN and PReLU activation.\n","def decoder_block_simple(\n","        layer_name, block_name,\n","        num_filters=32,\n","        conv_dim=(3, 3)):\n","\n","    x_dec = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv'.format(block_name))(layer_name)\n","    x_dec = BatchNormalization(\n","        name='{}_bn'.format(block_name))(x_dec)\n","    x_dec = PReLU(\n","        name='{}_activation'.format(block_name))(x_dec)\n","\n","    return x_dec\n","\n","# Decoder block with bottleneck architecture, where middle conv layer\n","# is half the size of first and last, in order to compress representation.\n","# This type of architecture is supposed to retain most useful information.\n","def decoder_block_bottleneck(\n","        layer_name, block_name,\n","        num_filters=32,\n","        conv_dim=(3, 3),\n","        dropout_frac=0.2):\n","\n","    x_dec = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv1'.format(block_name))(layer_name)\n","    x_dec = BatchNormalization(\n","        name='{}_bn1'.format(block_name))(x_dec)\n","    x_dec = PReLU(\n","        name='{}_activation1'.format(block_name))(x_dec)\n","    x_dec = Dropout(dropout_frac)(x_dec)\n","\n","    x_dec2 = Conv2D(\n","        num_filters // 2, conv_dim,\n","        padding='same',\n","        name='{}_conv2'.format(block_name))(x_dec)\n","    x_dec2 = BatchNormalization(\n","        name='{}_bn2'.format(block_name))(x_dec2)\n","    x_dec2 = PReLU(\n","        name='{}_activation2'.format(block_name))(x_dec2)\n","    x_dec2 = Dropout(dropout_frac)(x_dec2)\n","\n","    x_dec2 = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv3'.format(block_name))(x_dec2)\n","    x_dec2 = BatchNormalization(\n","        name='{}_bn3'.format(block_name))(x_dec2)\n","    x_dec2 = PReLU(\n","        name='{}_activation3'.format(block_name))(x_dec2)\n","    x_dec2 = Dropout(dropout_frac)(x_dec2)\n","\n","    x_dec2 = Add()([x_dec, x_dec2])\n","\n","    return x_dec2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pny2xUK6FVJM","colab_type":"text"},"source":["### Model definition:\n","\n","Combine encoder and decoder blocks to create final segmentation model."]},{"cell_type":"code","metadata":{"id":"kJlQGSBdFVJN","colab_type":"code","colab":{}},"source":["# Model is parametrized in a way to enable easy change of decoder_block type,\n","# as this is an argument that can be given a function, like decoder_block_simple.\n","def unet_VGG(input_size, decoder_block,\n","                weights='imagenet',#データセットで学習した重み\n","                loss_func='binary_crossentropy',\n","                metrics_list=[my_iou_metric],\n","                use_lovash=False):\n","\n","    # Base model - encoder\n","    base_model = VGG16(\n","        input_shape=input_size, \n","        include_top=False,\n","        weights=weights)\n","    \n","    # Layers for feature extraction in the encoder part\n","    encoder1 = base_model.get_layer('block2_conv2').output\n","    encoder2 = base_model.get_layer('block3_conv3').output\n","    encoder3 = base_model.get_layer('block4_conv3').output\n","    encoder4 = base_model.get_layer('block5_conv3').output\n","    encoder5 = base_model.get_layer('block5_pool').output\n","\n","    # Center block\n","    center = decoder_block(\n","        encoder5, 'center', num_filters=512)\n","    concat5 = concatenate([center, encoder5], axis=-1)\n","\n","    # Decoder part.\n","    # Every decoder block processed concatenated output from encoder and decoder part.\n","    # This creates skip connections.\n","    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n","    decoder4 = decoder_block(\n","        concat5, 'decoder4', num_filters=256)\n","    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n","\n","    decoder3 = decoder_block(\n","        concat4, 'decoder3', num_filters=128)\n","    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n","\n","    decoder2 = decoder_block(\n","        concat3, 'decoder2', num_filters=64)\n","    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n","\n","    decoder1 = decoder_block(\n","        concat2, 'decoder1', num_filters=64)\n","    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n","\n","    # Final upsampling and decoder block for segmentation.\n","    output = UpSampling2D()(concat1)\n","    output = decoder_block(\n","        output, 'decoder_output', num_filters=32)\n","    output = Conv2D(\n","        1, (1, 1), activation=None, name='prediction')(output)\n","    if not use_lovash:\n","        output = Activation('sigmoid')(output)\n","        \n","    model = Model(base_model.input, output)\n","    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PghQz8kLFVJP","colab_type":"text"},"source":["### Inspect created model:"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"rymYzVz-FVJP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e01079c9-bad4-43cf-8897-cee35163bf8c","executionInfo":{"status":"ok","timestamp":1569410190988,"user_tz":-540,"elapsed":30494,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["input_size = (224, 224, 3)\n","\n","\n","K.clear_session()\n","model = unet_VGG(\n","    input_size, decoder_block_simple, weights='imagenet')\n","model.summary()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From <ipython-input-21-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n","__________________________________________________________________________________________________\n","block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n","__________________________________________________________________________________________________\n","center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n","__________________________________________________________________________________________________\n","center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n","                                                                 block5_pool[0][0]                \n","__________________________________________________________________________________________________\n","decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n","                                                                 block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n","                                                                 block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n","                                                                 block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n","                                                                 block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","decoder_output_conv (Conv2D)    (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n","__________________________________________________________________________________________________\n","decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n","__________________________________________________________________________________________________\n","prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n","==================================================================================================\n","Total params: 22,850,817\n","Trainable params: 22,848,705\n","Non-trainable params: 2,112\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LbD5tKXgFVJS","colab_type":"text"},"source":["### Train model:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"nVRbtG75FVJS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"91154698-210c-42c0-b683-d58f6a8c3a53","executionInfo":{"status":"ok","timestamp":1569410271617,"user_tz":-540,"elapsed":111105,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["K.clear_session()\n","\n","# Build model:\n","# Here, you can experiment with various losses.\n","# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n","# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n","# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n","# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n","# This is controlled by use_lovash parameter.\n","model_depth = unet_VGG(\n","    input_size, decoder_block_bottleneck, weights='imagenet',\n","    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n","    use_lovash=False)\n","print(model_depth.summary())\n","\n","\n","model_checkpoint = ModelCheckpoint(\n","    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n","    save_best_only=True, save_weights_only=True, verbose=1)\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_my_iou_metric',\n","    mode='max',\n","    factor=0.5, \n","    patience=5, \n","    min_lr=0.0001, \n","    verbose=1)\n","\n","\n","epochs = 2  # 25\n","batch_size = 16\n","\n","history = model_depth.fit(X_tr, y_tr,\n","                    validation_data=[X_val, y_val], \n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    callbacks=[model_checkpoint,reduce_lr], \n","                    verbose=1)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n","__________________________________________________________________________________________________\n","block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n","__________________________________________________________________________________________________\n","center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n","__________________________________________________________________________________________________\n","center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n","__________________________________________________________________________________________________\n","center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n","__________________________________________________________________________________________________\n","center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n","__________________________________________________________________________________________________\n","center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n","__________________________________________________________________________________________________\n","center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n","                                                                 dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n","                                                                 block5_pool[0][0]                \n","__________________________________________________________________________________________________\n","decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n","                                                                 dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n","                                                                 block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n","                                                                 dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n","                                                                 block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n","                                                                 dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n","                                                                 block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n","                                                                 dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n","                                                                 block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n","__________________________________________________________________________________________________\n","decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n","__________________________________________________________________________________________________\n","decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n","==================================================================================================\n","Total params: 28,917,105\n","Trainable params: 28,911,825\n","Non-trainable params: 5,280\n","__________________________________________________________________________________________________\n","None\n","Train on 234 samples, validate on 66 samples\n","Epoch 1/2\n","234/234 [==============================] - 42s 178ms/step - loss: 1.1578 - my_iou_metric: 0.0543 - val_loss: 2.4460 - val_my_iou_metric: 0.0303\n","\n","Epoch 00001: val_my_iou_metric improved from -inf to 0.03030, saving model to unet_resnet.h5\n","Epoch 2/2\n","234/234 [==============================] - 17s 75ms/step - loss: 1.0339 - my_iou_metric: 0.0936 - val_loss: 1.3719 - val_my_iou_metric: 0.0303\n","\n","Epoch 00002: val_my_iou_metric did not improve from 0.03030\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zjDh9QgCFVJW","colab_type":"text"},"source":["### Validation set prediction and resizing to original size:"]},{"cell_type":"code","metadata":{"id":"avGW5gcDFVJX","colab_type":"code","colab":{}},"source":["val_preds = model_depth.predict(X_val, batch_size=16)\n","\n","y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n","y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OPk9ulocFVJc","colab_type":"text"},"source":["### Threshold optimization: "]},{"cell_type":"code","metadata":{"id":"YDpCJOjTFVJc","colab_type":"code","colab":{}},"source":["# src: https://www.kaggle.com/aglotero/another-iou-metric\n","def iou_metric(y_true_in, y_pred_in, print_table=False):\n","    labels = y_true_in\n","    y_pred = y_pred_in\n","    \n","    true_objects = 2\n","    pred_objects = 2\n","\n","    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n","\n","    # Compute areas (needed for finding the union between all objects)\n","    area_true = np.histogram(labels, bins = true_objects)[0]\n","    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n","    area_true = np.expand_dims(area_true, -1)\n","    area_pred = np.expand_dims(area_pred, 0)\n","\n","    # Compute union\n","    union = area_true + area_pred - intersection\n","\n","    # Exclude background from the analysis\n","    intersection = intersection[1:,1:]\n","    union = union[1:,1:]\n","    union[union == 0] = 1e-9\n","\n","    # Compute the intersection over union\n","    iou = intersection / union\n","\n","    # Precision helper function\n","    def precision_at(threshold, iou):\n","        matches = iou > threshold\n","        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n","        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n","        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n","        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n","        return tp, fp, fn\n","\n","    # Loop over IoU thresholds\n","    prec = []\n","    if print_table:\n","        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        tp, fp, fn = precision_at(t, iou)\n","        if (tp + fp + fn) > 0:\n","            p = tp / (tp + fp + fn)\n","        else:\n","            p = 0\n","        if print_table:\n","            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n","        prec.append(p)\n","    \n","    if print_table:\n","        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n","    return np.mean(prec)\n","\n","def iou_metric_batch(y_true_in, y_pred_in):\n","    batch_size = y_true_in.shape[0]\n","    metric = []\n","    for batch in range(batch_size):\n","        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n","        metric.append(value)\n","    return np.mean(metric)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Fl9SETtFVJg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8fe744de-23ae-4b21-cf81-8508232583d7","executionInfo":{"status":"ok","timestamp":1569410277368,"user_tz":-540,"elapsed":116828,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["# Threshold range, over which optimization is performed\n","thresholds = np.arange(0.2, 0.9, 0.02)\n","\n","# For every threshold, set predictions to binary arrays, \n","# where values above threshold are treated as 1 and the rest as 0.\n","# Loop over thresholds and compute IoU for them based on IoU function above.\n","ious = np.array(\n","    [iou_metric_batch(y_val_true,\n","                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["100%|██████████| 35/35 [00:03<00:00,  8.76it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tnFzssymFVJj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"ee01295a-27a9-4f93-ef5d-7e7caa20a845","executionInfo":{"status":"ok","timestamp":1569410277369,"user_tz":-540,"elapsed":116819,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n","df_iou['iou'] = ious\n","\n","# Get index of best IoU\n","best_index = df_iou['iou'].idxmax()\n","print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n","    df_iou.iou[best_index], df_iou.threshold[best_index]))\n","\n","# Describe IoU DF\n","df_iou.describe()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Best IoU: 0.5182 at threshold: 0.840\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>iou</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>35.000000</td>\n","      <td>35.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.540000</td>\n","      <td>0.156017</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.204939</td>\n","      <td>0.180298</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.200000</td>\n","      <td>0.030303</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.370000</td>\n","      <td>0.030303</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.540000</td>\n","      <td>0.053030</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.710000</td>\n","      <td>0.255303</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.880000</td>\n","      <td>0.518182</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       threshold        iou\n","count  35.000000  35.000000\n","mean    0.540000   0.156017\n","std     0.204939   0.180298\n","min     0.200000   0.030303\n","25%     0.370000   0.030303\n","50%     0.540000   0.053030\n","75%     0.710000   0.255303\n","max     0.880000   0.518182"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"PuWs_E4dFVJl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":572},"outputId":"462ca61a-4eea-41a9-bfd7-5cc8376e66f3","executionInfo":{"status":"ok","timestamp":1569410278068,"user_tz":-540,"elapsed":117508,"user":{"displayName":"高森祐樹","photoUrl":"","userId":"00608275060935750907"}}},"source":["# Plot IoU values over threshold range.\n","df_iou.plot(x='threshold', y='iou')"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f5084acc7b8>"]},"metadata":{"tags":[]},"execution_count":32},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAsYAAAIaCAYAAAAjlIvhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 864x648 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"4YuFHa84FVJq","colab_type":"text"},"source":["## Conclusions:\n","\n","- Pretrained models can be used for segmentation problems:\n","    - Some of architectures can be easily adapted to the problem (ie ResNet)\n","    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n","    - You can experiment with selection of layers for feature extraction\n","    - For some models, you can also try to experiment with number of encoder/decoder blocks\n","- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n","    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n","- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n","    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n","\n","\n","### Possible experiments:\n","\n","- Change type of decoder block in created segmentation model\n","- Create your own decoder blocks\n","- Train with other losses\n","- Train longer\n","- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n","- Try different ranges and intervals for threshold optimization"]},{"cell_type":"code","metadata":{"id":"mIDdqriGFVJq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}