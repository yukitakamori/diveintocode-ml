{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint ディープラーニングフレームワーク2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 公式Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】公式Exampleを分担して実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以下を実行\n",
    "https://www.tensorflow.org/tutorials/keras/basic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 車に関する、7個の特徴量から燃費を推測する問題\n",
    "- ３層のニューラルネットワークを用いた\n",
    "-　結果としては、テストデータの正解値と予測値で散布図を表示したところ線形となったので、それなりの成果が出ているようだ\n",
    "- １００エポック以上からロスが上がっているので、学習を止めた方が良い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】Iris（2値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0127 16:24:54.174554 4446201280 deprecation.py:506] From /Users/takamoriyuki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0127 16:24:54.312721 4446201280 deprecation.py:323] From /Users/takamoriyuki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(100, activation = tf.nn.relu, input_shape=(4,)),\n",
    "            tf.keras.layers.Dense(100, activation = tf.nn.relu),\n",
    "            tf.keras.layers.Dense(1, activation = tf.nn.sigmoid)])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,701\n",
      "Trainable params: 10,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.8497 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 0.6631 - acc: 0.6406\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 0.5600 - acc: 0.5625\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 345us/sample - loss: 0.5035 - acc: 0.7656\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 379us/sample - loss: 0.4240 - acc: 0.9375\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4914 - acc: 0.6562\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 0.4855 - acc: 0.6875\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 0.5149 - acc: 0.6250\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 349us/sample - loss: 0.3399 - acc: 0.8750\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 0.2805 - acc: 0.9219\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 0.2731 - acc: 0.9062\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 139us/sample - loss: 0.2093 - acc: 0.9531\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.2177 - acc: 0.9219\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 0.1880 - acc: 0.9531\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 0.1771 - acc: 0.9219\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 191us/sample - loss: 0.1510 - acc: 0.9531\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 207us/sample - loss: 0.1621 - acc: 0.9375\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 206us/sample - loss: 0.1404 - acc: 0.9219\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 0.1610 - acc: 0.9375\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 183us/sample - loss: 0.1071 - acc: 0.9844\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 190us/sample - loss: 0.1076 - acc: 0.9844\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 184us/sample - loss: 0.1891 - acc: 0.9375\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 0.1315 - acc: 0.9062\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 0.1082 - acc: 0.9531\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 143us/sample - loss: 0.0962 - acc: 0.9688\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 191us/sample - loss: 0.0866 - acc: 0.9688\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 189us/sample - loss: 0.0991 - acc: 0.9531\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 190us/sample - loss: 0.1528 - acc: 0.9375\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 146us/sample - loss: 0.0720 - acc: 0.9844\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 149us/sample - loss: 0.0908 - acc: 0.9531\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 0.0956 - acc: 0.9375\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 0.0691 - acc: 0.9844\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 0.0650 - acc: 0.9688\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 194us/sample - loss: 0.0854 - acc: 0.9531\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 194us/sample - loss: 0.1160 - acc: 0.9375\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 196us/sample - loss: 0.1008 - acc: 0.9375\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 0.1051 - acc: 0.9375\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.2726 - acc: 0.9062\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 0.4532 - acc: 0.8438\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 170us/sample - loss: 0.5517 - acc: 0.8281\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 123us/sample - loss: 0.2395 - acc: 0.8906\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 127us/sample - loss: 0.4302 - acc: 0.8438\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 161us/sample - loss: 0.2210 - acc: 0.9219\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 170us/sample - loss: 0.2495 - acc: 0.8750\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 0.1513 - acc: 0.9375\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 132us/sample - loss: 0.1350 - acc: 0.9531\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 144us/sample - loss: 0.1011 - acc: 0.9844\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 146us/sample - loss: 0.0895 - acc: 0.9688\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 133us/sample - loss: 0.0884 - acc: 0.9688\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 126us/sample - loss: 0.1182 - acc: 0.9375\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 0.0659 - acc: 0.9844\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 131us/sample - loss: 0.0916 - acc: 0.9688\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 134us/sample - loss: 0.1281 - acc: 0.9375\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 138us/sample - loss: 0.1209 - acc: 0.9531\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 128us/sample - loss: 0.0820 - acc: 0.9531\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 159us/sample - loss: 0.1789 - acc: 0.9375\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 175us/sample - loss: 0.1091 - acc: 0.9531\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 144us/sample - loss: 0.0520 - acc: 0.9844\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 178us/sample - loss: 0.1243 - acc: 0.9375\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 179us/sample - loss: 0.0668 - acc: 0.9688\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 167us/sample - loss: 0.0750 - acc: 0.9844\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 145us/sample - loss: 0.0661 - acc: 0.9688\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 173us/sample - loss: 0.0548 - acc: 0.9688\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 143us/sample - loss: 0.0597 - acc: 0.9844\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 128us/sample - loss: 0.0573 - acc: 0.9844\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 127us/sample - loss: 0.0639 - acc: 0.9844\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 145us/sample - loss: 0.0495 - acc: 0.9844\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 152us/sample - loss: 0.0554 - acc: 0.9688\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 129us/sample - loss: 0.0524 - acc: 0.9844\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 130us/sample - loss: 0.0549 - acc: 0.9688\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 136us/sample - loss: 0.0546 - acc: 0.9688\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 165us/sample - loss: 0.0484 - acc: 0.9844\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 135us/sample - loss: 0.0618 - acc: 0.9688\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 160us/sample - loss: 0.2196 - acc: 0.9375\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 145us/sample - loss: 0.0681 - acc: 0.9688\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 191us/sample - loss: 0.1828 - acc: 0.9219\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 184us/sample - loss: 0.1258 - acc: 0.9375\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 129us/sample - loss: 0.1949 - acc: 0.9375\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 150us/sample - loss: 0.4578 - acc: 0.8906\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 0.3372 - acc: 0.8906\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 142us/sample - loss: 0.1362 - acc: 0.9375\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 124us/sample - loss: 0.1784 - acc: 0.9062\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 123us/sample - loss: 0.2020 - acc: 0.8906\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 137us/sample - loss: 0.3231 - acc: 0.8750\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 130us/sample - loss: 0.0973 - acc: 0.9375\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 0.1153 - acc: 0.9375\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 129us/sample - loss: 0.0967 - acc: 0.9375\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 147us/sample - loss: 0.1417 - acc: 0.9375\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 148us/sample - loss: 0.0653 - acc: 0.9844\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 154us/sample - loss: 0.0611 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 126us/sample - loss: 0.0958 - acc: 0.9531\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 159us/sample - loss: 0.1283 - acc: 0.9219\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 129us/sample - loss: 0.1130 - acc: 0.9375\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 137us/sample - loss: 0.0701 - acc: 0.9531\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 0.0696 - acc: 0.9844\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 154us/sample - loss: 0.0631 - acc: 0.9844\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 147us/sample - loss: 0.0595 - acc: 0.9688\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 176us/sample - loss: 0.0999 - acc: 0.9375\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 151us/sample - loss: 0.0624 - acc: 0.9688\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 150us/sample - loss: 0.0970 - acc: 0.9531\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=20,\n",
    "                    epochs=100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_proba [9.9646831e-01 1.3228953e-03 9.8513961e-01 7.7947974e-04 9.9117655e-01\n",
      " 7.4751377e-03 7.6085329e-04 7.1415007e-03 9.8847318e-01 9.9176437e-01\n",
      " 6.6092610e-04 9.5795333e-01 7.1525574e-03 6.2714028e-01 6.4192683e-01\n",
      " 1.4682114e-03 1.7734513e-01 9.8462987e-01 1.9360483e-03 9.9873096e-01\n",
      " 9.9954593e-01 7.0107579e-03 8.9735305e-01 9.9949580e-01 9.9905175e-01\n",
      " 8.9084804e-03 9.9654657e-01 4.5332313e-04 9.9333346e-01 9.9734974e-01\n",
      " 9.9802476e-01 9.9722791e-01 1.9849718e-02 9.8707151e-01 7.2488189e-03\n",
      " 9.9991500e-01 9.9867541e-01 8.1253052e-04 1.0638833e-03 1.6502753e-01\n",
      " 2.5096536e-04 8.3263403e-01 3.3255386e-01 1.7467141e-04 1.6741753e-03\n",
      " 9.9611282e-03 9.9958503e-01 9.9998713e-01 4.0960312e-04 5.1632226e-03\n",
      " 7.6451898e-04 9.9896383e-01 9.9762386e-01 9.9986148e-01 9.9940765e-01\n",
      " 9.9034894e-01 3.4261644e-03 9.9632108e-01 8.0221373e-01 9.9923354e-01\n",
      " 1.0303557e-03 7.0268810e-03 9.9523157e-01 8.9007115e-01]\n",
      "y_pred [1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1\n",
      " 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_train)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 1)\n",
      "(96, 3)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df3 = pd.read_csv(dataset_path)\n",
    "\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df3 = df3[(df3[\"Species\"] == \"Iris-versicolor\")|(df3[\"Species\"] == \"Iris-virginica\")|(df3[\"Species\"] == \"Iris-setosa\")]\n",
    "y = df3[\"Species\"]\n",
    "X = df3.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test3, y_train, y_test3 = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train3, X_val3, y_train3, y_val3 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot3 = enc.fit_transform(y_train3)#[:, np.newaxis])\n",
    "y_test_one_hot3 = enc.transform(y_test3)#[:, np.newaxis])\n",
    "\n",
    "print(y_train3.shape) # (60000,)\n",
    "print(y_train_one_hot3.shape) # (60000, 10)\n",
    "print(y_train_one_hot3.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(4,)),\n",
    "            tf.keras.layers.Dense(100, activation = tf.nn.relu),\n",
    "            tf.keras.layers.Dense(3, activation = tf.nn.softmax)])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "96/96 [==============================] - 0s 865us/sample - loss: 0.9294 - acc: 0.5938\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 307us/sample - loss: 0.4738 - acc: 0.7812\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 136us/sample - loss: 0.4206 - acc: 0.7188\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 163us/sample - loss: 0.3226 - acc: 0.8333\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 181us/sample - loss: 0.2405 - acc: 0.8646\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 170us/sample - loss: 0.2196 - acc: 0.9271\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 189us/sample - loss: 0.1897 - acc: 0.8854\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 176us/sample - loss: 0.1212 - acc: 0.9688\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 199us/sample - loss: 0.1062 - acc: 0.9688\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 178us/sample - loss: 0.0941 - acc: 0.9688\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 163us/sample - loss: 0.0800 - acc: 0.9792\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 180us/sample - loss: 0.0756 - acc: 0.9792\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 212us/sample - loss: 0.1037 - acc: 0.9583\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 219us/sample - loss: 0.2190 - acc: 0.8958\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 170us/sample - loss: 0.2108 - acc: 0.9167\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 160us/sample - loss: 0.2364 - acc: 0.9167\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 218us/sample - loss: 0.2682 - acc: 0.8854\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 148us/sample - loss: 0.3848 - acc: 0.8750\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 153us/sample - loss: 0.1921 - acc: 0.9062\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 149us/sample - loss: 0.1679 - acc: 0.9583\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 172us/sample - loss: 0.1582 - acc: 0.9167\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 167us/sample - loss: 0.0986 - acc: 0.9583\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 143us/sample - loss: 0.0717 - acc: 0.9583\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 155us/sample - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 198us/sample - loss: 0.0653 - acc: 0.9792\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 163us/sample - loss: 0.0416 - acc: 0.9792\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 159us/sample - loss: 0.0574 - acc: 0.9688\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 151us/sample - loss: 0.0467 - acc: 0.9792\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 139us/sample - loss: 0.0432 - acc: 0.9688\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 150us/sample - loss: 0.0367 - acc: 0.9896\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 165us/sample - loss: 0.0497 - acc: 0.9792\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 174us/sample - loss: 0.0459 - acc: 0.9792\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 165us/sample - loss: 0.0326 - acc: 0.9896\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 185us/sample - loss: 0.0353 - acc: 0.9792\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 159us/sample - loss: 0.0371 - acc: 0.9792\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 151us/sample - loss: 0.0338 - acc: 0.9896\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 159us/sample - loss: 0.0427 - acc: 0.9792\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 111us/sample - loss: 0.0469 - acc: 0.9896\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 106us/sample - loss: 0.0336 - acc: 0.9792\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 98us/sample - loss: 0.0366 - acc: 0.9896\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 121us/sample - loss: 0.0392 - acc: 0.9896\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 230us/sample - loss: 0.0320 - acc: 0.9792\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 148us/sample - loss: 0.0295 - acc: 0.9896\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 202us/sample - loss: 0.0346 - acc: 0.9896\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 125us/sample - loss: 0.1292 - acc: 0.9583\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 134us/sample - loss: 0.1726 - acc: 0.9479\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 106us/sample - loss: 0.0827 - acc: 0.9583\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 95us/sample - loss: 0.0459 - acc: 0.9688\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 96us/sample - loss: 0.0795 - acc: 0.9583\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 97us/sample - loss: 0.1248 - acc: 0.9375\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 109us/sample - loss: 0.1797 - acc: 0.9271\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 102us/sample - loss: 0.0704 - acc: 0.9583\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 105us/sample - loss: 0.0510 - acc: 0.9896\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 108us/sample - loss: 0.0506 - acc: 0.9792\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 126us/sample - loss: 0.0455 - acc: 0.9792\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.0300 - acc: 0.9896\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 96us/sample - loss: 0.0391 - acc: 0.9896\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 117us/sample - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 103us/sample - loss: 0.0276 - acc: 0.9896\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 106us/sample - loss: 0.0389 - acc: 0.9896\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 131us/sample - loss: 0.0649 - acc: 0.9792\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 127us/sample - loss: 0.0533 - acc: 0.9688\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 109us/sample - loss: 0.0395 - acc: 0.9792\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 104us/sample - loss: 0.0309 - acc: 0.9896\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 106us/sample - loss: 0.0291 - acc: 0.9896\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.0277 - acc: 0.9896\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 97us/sample - loss: 0.0282 - acc: 0.9896\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 111us/sample - loss: 0.0312 - acc: 0.9896\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 137us/sample - loss: 0.0316 - acc: 0.9896\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 104us/sample - loss: 0.0264 - acc: 0.9896\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 101us/sample - loss: 0.0359 - acc: 0.9792\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 115us/sample - loss: 0.0203 - acc: 0.9896\n",
      "Epoch 75/100\n",
      "96/96 [==============================] - 0s 103us/sample - loss: 0.0722 - acc: 0.9688\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 98us/sample - loss: 0.0462 - acc: 0.9688\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 104us/sample - loss: 0.0508 - acc: 0.9792\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 103us/sample - loss: 0.0343 - acc: 0.9792\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 96us/sample - loss: 0.0418 - acc: 0.9792\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 127us/sample - loss: 0.0435 - acc: 0.9792\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 102us/sample - loss: 0.0461 - acc: 0.9688\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 100us/sample - loss: 0.0340 - acc: 0.9792\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 123us/sample - loss: 0.0226 - acc: 0.9896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 105us/sample - loss: 0.0244 - acc: 0.9792\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 0s 112us/sample - loss: 0.0216 - acc: 0.9896\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 106us/sample - loss: 0.0255 - acc: 0.9896\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 115us/sample - loss: 0.0227 - acc: 0.9896\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 126us/sample - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 105us/sample - loss: 0.0367 - acc: 0.9688\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 102us/sample - loss: 0.0426 - acc: 0.9896\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 0s 89us/sample - loss: 0.0790 - acc: 0.9792\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.2026 - acc: 0.9271\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 0s 120us/sample - loss: 0.0519 - acc: 0.9792\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 0s 123us/sample - loss: 0.0332 - acc: 0.9896\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 0s 158us/sample - loss: 0.0342 - acc: 0.9896\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 0s 95us/sample - loss: 0.0281 - acc: 0.9896\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.0243 - acc: 0.9896\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 0s 91us/sample - loss: 0.0261 - acc: 0.9896\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.0245 - acc: 0.9896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train3, y_train_one_hot3,\n",
    "                    batch_size=20,\n",
    "                    epochs=100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_proba [[3.00842395e-09 9.96846720e-05 9.99900341e-01]\n",
      " [6.98223157e-05 9.99915361e-01 1.47973560e-05]\n",
      " [1.00000000e+00 1.89883465e-09 1.30317762e-21]\n",
      " [5.02804332e-09 2.44648574e-04 9.99755323e-01]\n",
      " [9.99999166e-01 7.83067435e-07 1.75317109e-17]\n",
      " [3.66197524e-11 1.10757037e-05 9.99988914e-01]\n",
      " [9.99999881e-01 1.41575384e-07 2.18913535e-18]\n",
      " [4.64889345e-05 9.99630213e-01 3.23259883e-04]\n",
      " [5.53820100e-05 9.99240637e-01 7.04024686e-04]\n",
      " [4.53017965e-05 9.99947548e-01 7.09792448e-06]\n",
      " [8.78590853e-08 1.16239034e-03 9.98837531e-01]\n",
      " [5.14846397e-05 9.99764979e-01 1.83571959e-04]\n",
      " [9.33427073e-05 9.95948672e-01 3.95800732e-03]\n",
      " [9.55110154e-05 9.98047352e-01 1.85705384e-03]\n",
      " [1.18191543e-04 9.70468342e-01 2.94133890e-02]\n",
      " [9.99995470e-01 4.50040579e-06 1.50948511e-16]\n",
      " [1.54552545e-04 9.82737958e-01 1.71074998e-02]\n",
      " [2.17985275e-04 9.64927733e-01 3.48542519e-02]\n",
      " [9.99992371e-01 7.59669729e-06 7.88014074e-16]\n",
      " [1.00000000e+00 1.16498455e-08 3.52661733e-20]\n",
      " [5.47323715e-08 4.69630962e-04 9.99530315e-01]\n",
      " [1.72705913e-04 7.47250319e-01 2.52576977e-01]\n",
      " [9.99986410e-01 1.35625169e-05 2.10774493e-15]\n",
      " [9.99986410e-01 1.35715218e-05 4.17552049e-15]\n",
      " [1.42107219e-05 4.62299176e-02 9.53755856e-01]\n",
      " [1.00000000e+00 9.80366188e-09 1.17643061e-19]\n",
      " [9.99998450e-01 1.57035663e-06 1.05277705e-16]\n",
      " [5.28415330e-05 9.99902844e-01 4.43380122e-05]\n",
      " [1.54385096e-04 9.99839544e-01 6.02967066e-06]\n",
      " [9.99997377e-01 2.67410815e-06 2.03643635e-16]]\n",
      "y_pred [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test3)#[:, 0]\n",
    "\n",
    "\n",
    "# 確率を0,1,2に変換\n",
    "y_pred3 = np.argmax(y_pred_proba , axis=1)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(y_test3, (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】House PricesをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"./housing_price_train.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "y = y[:, np.newaxis]\n",
    "# yを対数変換\n",
    "X = np.log(X)\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,351\n",
      "Trainable params: 5,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 6261673843.7260275\n",
      "Test mse: 6261673500.0\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(2,)))\n",
    "model.add(tf.keras.layers.Dense(100, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate),\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# 指標値\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test mse:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】MNISTをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 443,610\n",
      "Trainable params: 443,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 20s 417us/sample - loss: 0.3808 - acc: 0.8982 - val_loss: 0.2824 - val_acc: 0.9287\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 19s 388us/sample - loss: 0.2773 - acc: 0.9337 - val_loss: 0.2845 - val_acc: 0.9391\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 17s 345us/sample - loss: 0.2430 - acc: 0.9432 - val_loss: 0.2818 - val_acc: 0.9460\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 17s 360us/sample - loss: 0.2287 - acc: 0.9485 - val_loss: 0.2118 - val_acc: 0.9566\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 17s 348us/sample - loss: 0.2165 - acc: 0.9519 - val_loss: 0.2758 - val_acc: 0.9473\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 17s 362us/sample - loss: 0.2341 - acc: 0.9490 - val_loss: 0.3528 - val_acc: 0.9341\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 16s 328us/sample - loss: 0.2364 - acc: 0.9496 - val_loss: 0.2728 - val_acc: 0.9410\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 15s 321us/sample - loss: 0.2303 - acc: 0.9464 - val_loss: 0.3093 - val_acc: 0.9483\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 15s 319us/sample - loss: 0.2373 - acc: 0.9456 - val_loss: 0.3599 - val_acc: 0.9322\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 17s 344us/sample - loss: 0.2211 - acc: 0.9475 - val_loss: 0.4077 - val_acc: 0.8848\n",
      "Test loss: 0.4495713760972023\n",
      "Test accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(500, activation = tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(100, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_train)\n",
    "\n",
    "# 確率の一番高いインデックスに変換\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
