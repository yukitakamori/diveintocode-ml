{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1次元の畳み込みニューラルネットワークスクラッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期化方法のクラス化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma = 0.01):\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self,n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化手法のクラス化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        print(layer.W)\n",
    "        layer.W = layer.W - self.lr * layer.L_w\n",
    "        layer.B = layer.B - self.lr * layer.L_b\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self,X):\n",
    "        self.mask = (X <= 0)\n",
    "        out = X.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss = None #損失\n",
    "        self.y = None #softmax output\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.y = np.exp(A) /np.reshape(np.sum(np.exp(A), axis=1),(-1,1))\n",
    "        return self.y\n",
    "\n",
    "    def backward(self, z, y):\n",
    "        self.dA = z - y\n",
    "        self.loss = -1 * (np.mean(np.sum(y*np.log(z+1e-5),axis=1),axis =0 ))\n",
    "\n",
    "        return self.dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全結合層のクラス化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer=SGD()):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        A = self.X@self.W + self.B\n",
    "       \n",
    "        return A\n",
    "    def backward(self, da):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        self.L_b = np.sum(da, axis = 0)\n",
    "        self.L_w = self.X.T@da\n",
    "        dz = da@self.W.T\n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 w, \n",
    "                 b,\n",
    "                 optimizer, \n",
    "                 stride=1, \n",
    "                 pad = 0):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "                \n",
    "        self.W = w\n",
    "        self.B = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.n_out = N_out(self.X,\n",
    "                      self.pad,\n",
    "                      self.W,\n",
    "                      self.stride)\n",
    "        \n",
    "        a = np.zeros(self.n_out)\n",
    "        for i in range(self.n_out):#2\n",
    "            a_i = 0\n",
    "            for s in range(len(self.W)):#3\n",
    "                a_i += self.X[i+s] * self.W[s]\n",
    "            a_i += self.B\n",
    "            a[i] = a_i\n",
    "\n",
    "        return a#(2)\n",
    "            \n",
    "    def backward(self, L_a):\n",
    "        self.L_a = L_a\n",
    "        for s in range(len(self.W)):#3\n",
    "            self.L_w = 0\n",
    "            self.L_b = 0\n",
    "            for i in range(len(self.W)-1):#3-1\n",
    "                self.L_w += self.L_a[i] * self.X[i+s]\n",
    "                self.L_b += self.L_a[i]\n",
    "\n",
    "        L_x = []\n",
    "        for j in range(len(self.X)):#4\n",
    "            x_j = 0\n",
    "            for s in range(len(self.W)):#3\n",
    "                if (j-s)<0 or (j-s)>(self.n_out-1):\n",
    "                    x_j += 0\n",
    "                else:\n",
    "                    x_j += self.L_a[j-s] * self.W[s]\n",
    "            \n",
    "            L_x.append(x_j)\n",
    "                \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return L_x#(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_out(X, P, F, S):\n",
    "    if X.ndim == 1:\n",
    "        n_out = ((X.shape[0] + 2*P - len(F)) / S) + 1\n",
    "    elif X.ndim > 1:\n",
    "        n_out = ((X.shape[-1] + 2*P - F.shape[-1]) / S) + 1\n",
    "    \n",
    "    return int(n_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】小さな配列での1次元畳み込み層の実験\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_out(x,0,w,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35., 50.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SimpleConv1d(w,b,SGD(0.01))\n",
    "sc.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 110, 170, 140]\n"
     ]
    }
   ],
   "source": [
    "print(sc.backward(delta_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_nChanel:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 w, \n",
    "                 b,\n",
    "                 optimizer=SGD(0.01), \n",
    "                 stride=1, \n",
    "                 pad = 0):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "                \n",
    "        self.W = w\n",
    "        self.B = np.reshape(b,(-1,1))\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        out_cha, in_cha, fil_size = self.W.shape#3,2,3\n",
    "        feature_size = self.X.shape[1]\n",
    "        \n",
    "        self.n_out = N_out(self.X,\n",
    "                      self.pad,\n",
    "                      self.W,\n",
    "                      self.stride)\n",
    "        a = np.zeros((out_cha,self.n_out))#3,2\n",
    "        a_i = np.zeros(self.n_out)\n",
    "        for i in range(out_cha):#3\n",
    "            for s in range(self.n_out):#2\n",
    "                temp = np.sum(self.X[:,s:(fil_size+s)]*self.W[i],axis=1)#\n",
    "                temp = np.sum(temp,axis=0) \n",
    "                a_i[s] = temp\n",
    "            a[i] = a_i\n",
    "        \n",
    "        a += self.B\n",
    "\n",
    "        return a#3,2\n",
    "            \n",
    "    def backward(self, L_a):\n",
    "        self.L_a = L_a\n",
    "        out_cha, in_cha, fil_size = self.W.shape#3,2,3\n",
    "        feature_size = self.X.shape[1]\n",
    "        \n",
    "        self.L_b = np.sum(self.L_a, axis=1)\n",
    "        \n",
    "        self.L_w = np.zeros_like(self.W)\n",
    "        for g in range(out_cha):\n",
    "            for h in range(in_cha):\n",
    "                for i in range(fil_size):\n",
    "                    for j in range(fil_size -1):\n",
    "                        self.L_w[g, h, i] += L_a[g, j]*self.X[h, j+i]\n",
    "                        \n",
    "        L_x = np.zeros_like(self.X)\n",
    "        for g in range(out_cha):\n",
    "            for h in range(in_cha):\n",
    "                for j in range(feature_size):\n",
    "                    x_j=0\n",
    "                    for s in range(fil_size):\n",
    "                        if j-s < 0 or j-s > self.n_out -1:\n",
    "                            x_j += 0\n",
    "                        else:\n",
    "                            x_j += L_a[g, j-s] * self.W[g, h, s]\n",
    "                    L_x[h, j] += x_j\n",
    "    \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return L_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], \n",
    "              [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # (出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "delta_a2 = np.array([[21, 42], [32, 62], [5, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = Conv1d_nChanel(w,b,SGD(0.01))\n",
    "cc.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58, 166, 166, 108],\n",
       "       [ 58, 166, 166, 108]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.backward(delta_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】学習と推定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチサイズを考慮する\n",
    "class Conv1d_nChanel2:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 w, \n",
    "                 b,\n",
    "                 optimizer=SGD(0.01), \n",
    "                 stride=1, \n",
    "                 pad = 0):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "                \n",
    "        self.W = w\n",
    "        self.B = b####np.reshape(b,(-1,1))####(-1,1)\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self,X):\n",
    "        self.X = X\n",
    "        out_cha, in_cha, fil_size = self.W.shape#3,2,3\n",
    "        feature_size = self.X.shape[2]\n",
    "        sample_size = self.X.shape[0]\n",
    "        \n",
    "        self.n_out = N_out(self.X,\n",
    "                      self.pad,\n",
    "                      self.W,\n",
    "                      self.stride)\n",
    "        \n",
    "        a = np.zeros((sample_size,out_cha,self.n_out))\n",
    "        a_i = np.zeros(self.n_out)\n",
    "        for h in range(sample_size):\n",
    "            X = self.X[h]\n",
    "            for i in range(out_cha):\n",
    "                for s in range(self.n_out):\n",
    "                    temp = np.sum(X[:,s:(fil_size+s)]*self.W[i],axis=1)#\n",
    "                    temp = np.sum(temp,axis=0) \n",
    "                    a_i[s] = temp \n",
    "                a[h,i,:] = a_i\n",
    "            a[h] += np.reshape(self.B,(-1,1))####\n",
    "\n",
    "        return a\n",
    "            \n",
    "    def backward(self, L_a):\n",
    "        self.L_a = L_a\n",
    "        out_cha, in_cha, fil_size = self.W.shape#3,2,3\n",
    "        feature_size = self.X.shape[2]\n",
    "        sample_size = self.X.shape[0]\n",
    "        \n",
    "        self.L_b = np.sum(self.L_a, axis=0)\n",
    "        self.L_b = np.sum(self.L_b, axis=1)#####\n",
    "        self.L_w = np.zeros_like(self.W)\n",
    "        for f in range(sample_size):\n",
    "            for g in range(out_cha):\n",
    "                for h in range(in_cha):\n",
    "                    for i in range(fil_size):\n",
    "                        for j in range(fil_size -1):\n",
    "                            self.L_w[g, h, i] += L_a[f, g, j]*self.X[f, h, j+i]\n",
    "\n",
    "        L_x = np.zeros_like(self.X)\n",
    "        for f in range(sample_size):\n",
    "            for g in range(out_cha):\n",
    "                for h in range(in_cha):\n",
    "                    for j in range(feature_size):\n",
    "                        x_j=0\n",
    "                        for s in range(fil_size):\n",
    "                            if j-s < 0 or j-s > self.n_out-1:\n",
    "                                x_j += 0\n",
    "                            else:\n",
    "                                x_j += L_a[f, g, j-s] * self.W[g, h, s]\n",
    "                        L_x[f, h, j] += x_j\n",
    "\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return L_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.fit_transform(y_test[:,  np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 1, 784)\n",
    "X_test = X_test.reshape(-1, 1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.ones((3, 1, 3))\n",
    "b = np.array([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2 = Conv1d_nChanel2(w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cc2.forward(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3, 782)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = Relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_relu = relu.forward(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3, 782)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flatten = a_relu.reshape(a_relu.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2346)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC1 = FC(2346, 10, SimpleInitializer(), SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_FC1 = FC1.forward(a_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_softmax = softmax.forward(a_FC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_delta = softmax.backward(a_softmax, y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_L_a = FC1.backward(a_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2346)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_L_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_L_a_reshape = d_L_a.reshape(a_relu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3, 782)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_L_a_relu = relu.backward(d_L_a_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3, 782)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_L_a_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_x = cc2.backward(d_L_a_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc2.L_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-63.40827951, -39.28621084, -81.31902672])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc2.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = cc2.forward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = relu.forward(ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya  = ya.reshape(ya.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = FC1.forward(ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.max(ya, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ya.shape[0]):\n",
    "    ya[i] = np.exp(ya[i] - d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = softmax.forward(ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(ya, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0974\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
